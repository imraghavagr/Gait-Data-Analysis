{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "      <th>t</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>walkontoe</td>\n",
       "      <td>44:19.9</td>\n",
       "      <td>0.2129</td>\n",
       "      <td>-0.7217</td>\n",
       "      <td>1.6621</td>\n",
       "      <td>10.9253</td>\n",
       "      <td>23.0713</td>\n",
       "      <td>-8.6670</td>\n",
       "      <td>-34.5081</td>\n",
       "      <td>-8.3386</td>\n",
       "      <td>-1.0931</td>\n",
       "      <td>33.8534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>walkontoe</td>\n",
       "      <td>44:19.9</td>\n",
       "      <td>0.2188</td>\n",
       "      <td>-0.6841</td>\n",
       "      <td>1.7085</td>\n",
       "      <td>8.5449</td>\n",
       "      <td>24.7803</td>\n",
       "      <td>-6.6528</td>\n",
       "      <td>-34.3927</td>\n",
       "      <td>-8.1683</td>\n",
       "      <td>-1.2854</td>\n",
       "      <td>33.8564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>walkontoe</td>\n",
       "      <td>44:19.9</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>-0.6777</td>\n",
       "      <td>1.7251</td>\n",
       "      <td>0.1831</td>\n",
       "      <td>24.2310</td>\n",
       "      <td>-6.4697</td>\n",
       "      <td>-34.3652</td>\n",
       "      <td>-8.0035</td>\n",
       "      <td>-1.4777</td>\n",
       "      <td>33.8652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>walkontoe</td>\n",
       "      <td>44:19.9</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>-0.7075</td>\n",
       "      <td>1.6978</td>\n",
       "      <td>-9.2773</td>\n",
       "      <td>21.4844</td>\n",
       "      <td>-6.8359</td>\n",
       "      <td>-34.4312</td>\n",
       "      <td>-7.8662</td>\n",
       "      <td>-1.6589</td>\n",
       "      <td>33.8564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>walkontoe</td>\n",
       "      <td>44:19.9</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>-0.7476</td>\n",
       "      <td>1.6519</td>\n",
       "      <td>-12.8784</td>\n",
       "      <td>19.2261</td>\n",
       "      <td>-6.8359</td>\n",
       "      <td>-34.5355</td>\n",
       "      <td>-7.7454</td>\n",
       "      <td>-1.8237</td>\n",
       "      <td>33.8534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id          y        t      x1      x2      x3       x4       x5      x6  \\\n",
       "0   1  walkontoe  44:19.9  0.2129 -0.7217  1.6621  10.9253  23.0713 -8.6670   \n",
       "1   1  walkontoe  44:19.9  0.2188 -0.6841  1.7085   8.5449  24.7803 -6.6528   \n",
       "2   1  walkontoe  44:19.9  0.2300 -0.6777  1.7251   0.1831  24.2310 -6.4697   \n",
       "3   1  walkontoe  44:19.9  0.2358 -0.7075  1.6978  -9.2773  21.4844 -6.8359   \n",
       "4   1  walkontoe  44:19.9  0.2378 -0.7476  1.6519 -12.8784  19.2261 -6.8359   \n",
       "\n",
       "        x7      x8      x9      x10  \n",
       "0 -34.5081 -8.3386 -1.0931  33.8534  \n",
       "1 -34.3927 -8.1683 -1.2854  33.8564  \n",
       "2 -34.3652 -8.0035 -1.4777  33.8652  \n",
       "3 -34.4312 -7.8662 -1.6589  33.8564  \n",
       "4 -34.5355 -7.7454 -1.8237  33.8534  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72157 entries, 0 to 72156\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   id      72157 non-null  int64  \n",
      " 1   y       72157 non-null  object \n",
      " 2   t       72157 non-null  object \n",
      " 3   x1      72154 non-null  float64\n",
      " 4   x2      72154 non-null  float64\n",
      " 5   x3      72154 non-null  float64\n",
      " 6   x4      72154 non-null  float64\n",
      " 7   x5      72154 non-null  float64\n",
      " 8   x6      72154 non-null  float64\n",
      " 9   x7      72154 non-null  float64\n",
      " 10  x8      72154 non-null  float64\n",
      " 11  x9      72154 non-null  float64\n",
      " 12  x10     72154 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 7.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     0\n",
       "y      0\n",
       "t      0\n",
       "x1     3\n",
       "x2     3\n",
       "x3     3\n",
       "x4     3\n",
       "x5     3\n",
       "x6     3\n",
       "x7     3\n",
       "x8     3\n",
       "x9     3\n",
       "x10    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values by mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10']:\n",
    "    df[column]=df[column].fillna(df[column].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id     0\n",
       "y      0\n",
       "t      0\n",
       "x1     0\n",
       "x2     0\n",
       "x3     0\n",
       "x4     0\n",
       "x5     0\n",
       "x6     0\n",
       "x7     0\n",
       "x8     0\n",
       "x9     0\n",
       "x10    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.replace({'walkontoe':1, 'walkonheel':2, 'upstairs':3, 'downstairs':4, 'situps':5,'normalwalk':6, 'jogging':7, 'situp':8, 'upstair':9, 'downstair':10 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['y','t','id'],axis=1)\n",
    "y=df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    " - https://towardsdatascience.com/svm-classifier-and-rbf-kernel-how-to-make-better-models-in-python-73bb4914af5b\n",
    " - Radial Basis Function: 'rbf' - default kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm = SVC()\n",
    "svm.fit(X_train,y_train).score(X_test,y_test)\n",
    "svm_pred = svm.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.64      0.59      3113\n",
      "           2       0.46      0.64      0.53      2997\n",
      "           3       0.95      0.39      0.56       570\n",
      "           4       0.98      0.98      0.98       589\n",
      "           5       0.85      0.68      0.75       613\n",
      "           6       0.57      0.65      0.61      2447\n",
      "           7       0.80      0.69      0.74      2863\n",
      "           8       0.66      0.60      0.63      2118\n",
      "           9       0.86      0.54      0.66      1352\n",
      "          10       0.73      0.44      0.55      1378\n",
      "\n",
      "    accuracy                           0.63     18040\n",
      "   macro avg       0.74      0.62      0.66     18040\n",
      "weighted avg       0.66      0.63      0.63     18040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.173 total time= 8.9min\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.173 total time= 8.9min\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.173 total time= 9.0min\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.173 total time= 9.0min\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.173 total time= 9.0min\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.173 total time= 7.4min\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.173 total time= 7.4min\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.173 total time= 7.5min\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.174 total time= 7.4min\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.174 total time= 7.4min\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.409 total time= 4.2min\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.404 total time= 4.3min\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.406 total time= 4.2min\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.395 total time= 4.2min\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.398 total time= 4.3min\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.680 total time= 2.2min\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.669 total time= 2.1min\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.684 total time= 2.2min\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.676 total time= 2.1min\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.677 total time= 2.1min\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.573 total time= 1.8min\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.557 total time= 1.8min\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.571 total time= 1.8min\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.565 total time= 1.8min\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.565 total time= 1.8min\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.185 total time=10.7min\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.187 total time=10.7min\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.186 total time=10.7min\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.187 total time=10.6min\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.186 total time=10.7min\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.406 total time=10.8min\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.411 total time=10.8min\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.403 total time=10.8min\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.397 total time=10.8min\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.409 total time=10.8min\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.748 total time= 6.8min\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.745 total time= 6.8min\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.753 total time= 6.8min\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.746 total time= 6.8min\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.747 total time= 6.7min\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.824 total time= 1.8min\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.812 total time= 1.8min\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.826 total time= 1.8min\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.821 total time= 1.8min\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.817 total time= 1.8min\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.683 total time= 1.4min\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.676 total time= 1.4min\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.685 total time= 1.4min\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.683 total time= 1.4min\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.674 total time= 1.4min\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.191 total time=18.2min\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.194 total time=18.3min\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.192 total time=18.1min\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.194 total time=18.4min\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.194 total time=18.3min\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.440 total time=14.7min\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.447 total time=14.6min\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.440 total time=14.6min\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.431 total time=14.7min\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.443 total time=14.7min\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.781 total time= 7.5min\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.778 total time= 7.5min\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.781 total time= 7.5min\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.782 total time= 7.6min\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.881 total time= 1.8min\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.875 total time= 1.8min\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.883 total time= 1.9min\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.887 total time= 1.9min\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.878 total time= 1.8min\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.779 total time= 1.2min\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.769 total time= 1.2min\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.779 total time= 1.2min\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.775 total time= 1.2min\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.776 total time= 1.2min\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.191 total time=18.2min\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.194 total time=18.2min\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.192 total time=18.1min\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.194 total time=18.4min\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.194 total time=18.3min\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.440 total time=14.7min\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.447 total time=14.6min\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.440 total time=14.6min\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.431 total time=14.7min\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.443 total time=14.7min\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.778 total time= 7.5min\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.6min\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.782 total time= 7.5min\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.906 total time= 2.0min\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.900 total time= 2.1min\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.903 total time= 2.1min\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.910 total time= 2.1min\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.900 total time= 2.1min\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.853 total time= 1.3min\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.848 total time= 1.2min\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.850 total time= 1.3min\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.855 total time= 1.3min\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.848 total time= 1.2min\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.191 total time=18.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.194 total time=18.2min\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.192 total time=18.1min\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.194 total time=18.4min\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.194 total time=18.3min\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.440 total time=14.6min\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.447 total time=14.6min\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.440 total time=14.6min\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.431 total time=14.7min\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.443 total time=14.7min\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.778 total time= 7.5min\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.781 total time= 7.5min\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.780 total time= 7.5min\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.913 total time= 2.7min\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.906 total time= 2.6min\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.909 total time= 2.6min\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.914 total time= 2.6min\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.906 total time= 2.6min\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.885 total time= 2.2min\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.881 total time= 2.2min\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.886 total time= 2.2min\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.891 total time= 2.2min\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.881 total time= 2.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\n",
    "svm2 = SVC(kernel='poly')\n",
    "svm3 = SVC(kernel='poly',degree = 5)\n",
    "svm4 = SVC(kernel='sigmoid')\n",
    "svm5 = SVC(kernel='linear')\n",
    "svm6 = SVC(kernel='sigmoid')\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "SVC(C=1000, gamma=0.001)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.94      0.93      3113\n",
      "           2       0.89      0.88      0.88      2997\n",
      "           3       0.96      0.98      0.97       570\n",
      "           4       0.99      0.99      0.99       589\n",
      "           5       0.93      0.91      0.92       613\n",
      "           6       0.93      0.94      0.93      2447\n",
      "           7       0.89      0.90      0.89      2863\n",
      "           8       0.96      0.94      0.95      2118\n",
      "           9       0.98      0.97      0.97      1352\n",
      "          10       0.94      0.91      0.93      1378\n",
      "\n",
      "    accuracy                           0.92     18040\n",
      "   macro avg       0.94      0.94      0.94     18040\n",
      "weighted avg       0.92      0.92      0.92     18040\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying svc with kernel = poly\n",
    "svc_poly = SVC(kernel='poly',gamma=0.001,C=1000)\n",
    "svc_poly.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_pred = svc_poly.predict(X_test)\n",
    "print(classification_report(y_test,poly_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest + Linear SVC + Logistic Regression\n",
    "- without cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "   ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                           LinearSVC(random_state=42)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9951773835920177"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With cross validation\n",
    "\n",
    "- with cv = 5 (5 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators3 = [\n",
    "   ('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "    ('svr', make_pipeline(StandardScaler(),\n",
    "                           LinearSVC(random_state=42)))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = StackingClassifier(\n",
    "    cv = 5,estimators=estimators, final_estimator=LogisticRegression()\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=5,\n",
       "                   estimators=[('rf',\n",
       "                                RandomForestClassifier(n_estimators=10,\n",
       "                                                       random_state=42)),\n",
       "                               ('svr',\n",
       "                                Pipeline(steps=[('standardscaler',\n",
       "                                                 StandardScaler()),\n",
       "                                                ('linearsvc',\n",
       "                                                 LinearSVC(random_state=42))]))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)#.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9951773835920177"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv = 10 (10 fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9952328159645233"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = StackingClassifier(\n",
    "    cv = 10,estimators=estimators, final_estimator=LogisticRegression()\n",
    " )\n",
    "\n",
    "clf4.fit(X_train, y_train).score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT + KNN + Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators2 = [\n",
    "   ('knn1', KNeighborsClassifier(n_neighbors=3),\n",
    "    ('knn2', KNeighborsClassifier(n_neighbors=5),\n",
    "    'dt',DecisionTreeClassifier()))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\DIVYA THAKUR\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9951773835920177"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
